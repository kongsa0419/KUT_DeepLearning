{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 과목명: 딥러닝및실습 hw1_1\n",
    "##### 실습자: 2017136063 여승준"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d61321a42a27b7b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# a_tensor_initialization.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa02ea265d832dc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#pytorch's main package which is a tensor library\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.262481600Z",
     "start_time": "2023-09-19T13:12:22.546500Z"
    }
   },
   "id": "702351db80b62eee"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.Tensor([1,2,3], device='cpu')\n",
    "'''\n",
    "torch.'T'ensor = torch.FloatTensor이고,\n",
    "torch.'t'ensor = torch.LongTensor임. (생성자)\n",
    "\n",
    "미분에 관한 연산엔진을 내장하는 \n",
    "requires_grad 옵션은 , default = False\n",
    "'''\n",
    "print(t1.dtype)         # torch.float32\n",
    "print(t1.device)        # >>> cpu\n",
    "print(t1.requires_grad) # >>>False\n",
    "print(t1.size())        # torch.Size([3])\n",
    "print(t1.shape)         # torch.Size([3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.284488Z",
     "start_time": "2023-09-19T13:12:25.244205600Z"
    }
   },
   "id": "1c037e86967c3c40"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# if you have gpu device\n",
    "# t1_cuda = t1.to(torch.device('cuda')) #>>> error for me\n",
    "\n",
    "# or you can use shorthand (내 컴퓨터의 경우 t1.cuda()가 먹지 않았다.)\n",
    "#t1_cuda = t1.cuda()\n",
    "t1_cpu = t1.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.285489200Z",
     "start_time": "2023-09-19T13:12:25.267485900Z"
    }
   },
   "id": "21ef62fb8dd636a3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 1\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.348506900Z",
     "start_time": "2023-09-19T13:12:25.283487700Z"
    }
   },
   "id": "c67746ec04f942fc"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor function\n",
    "t2 = torch.tensor([1,2,3], device='cpu')\n",
    "print(t2.dtype) \n",
    "print(t2.device)\n",
    "print(t2.requires_grad)\n",
    "print(t2.size())\n",
    "print(t2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.348506900Z",
     "start_time": "2023-09-19T13:12:25.308494100Z"
    }
   },
   "id": "b9345cf4bbf420fe"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 2\n"
     ]
    }
   ],
   "source": [
    "# if you have gpu device\n",
    "# t2_cuda = t2.to(torch.device('cuda'))\n",
    "# or you can use shorthand\n",
    "# t2_cuda = t2.cuda()\n",
    "t2_cpu = t2.cpu()\n",
    "\n",
    "print(\"#\" * 50, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.350504800Z",
     "start_time": "2023-09-19T13:12:25.316495500Z"
    }
   },
   "id": "c6588a5b574dbdc4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텐서의 shape(=size)를 구하는 법, dimension을 구할 줄 알아야 함 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3e00b965c14b4db"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1)\t\t\t     # shape: torch.Size([]), ndims(=rank): 0\n",
    "print(a1.shape, a1.ndim)\n",
    "assert a1.shape == torch.Size([])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.350504800Z",
     "start_time": "2023-09-19T13:12:25.330499200Z"
    }
   },
   "id": "69ae7faf97992a86"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) 1\n",
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor([1])\t\t  \t     # shape: torch.Size([1]), ndims(=rank): 1\n",
    "print(a2.shape, a2.ndim)\n",
    "print(a2.dtype)\n",
    "assert a2.dtype == torch.int64\n",
    "\n",
    "a2_float = torch.as_tensor(a2, dtype=torch.float)\n",
    "print(a2_float.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.403528Z",
     "start_time": "2023-09-19T13:12:25.345514200Z"
    }
   },
   "id": "1d224692b506edec"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) 1\n"
     ]
    }
   ],
   "source": [
    "a3 = torch.tensor([1, 2, 3, 4, 5])   # shape: torch.Size([5]), ndims(=rank): 1\n",
    "print(a3.shape, a3.ndim)\n",
    "assert a3.shape==torch.Size([5])\n",
    "assert a3.ndim == 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.456528800Z",
     "start_time": "2023-09-19T13:12:25.362517400Z"
    }
   },
   "id": "85e4beeb061941f3"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1]) 2\n"
     ]
    }
   ],
   "source": [
    "a4 = torch.tensor([[1], [2], [3], [4], [5]])   # shape: torch.Size([5, 1]), ndims(=rank): 2\n",
    "print(a4.shape, a4.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.460529500Z",
     "start_time": "2023-09-19T13:12:25.379510100Z"
    }
   },
   "id": "88894deae1137f1e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) 2\n"
     ]
    }
   ],
   "source": [
    "a5 = torch.tensor([                 # shape: torch.Size([3, 2]), ndims(=rank): 2\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.485534600Z",
     "start_time": "2023-09-19T13:12:25.393513300Z"
    }
   },
   "id": "14022ea7cba10dd2"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 1]) 3\n"
     ]
    }
   ],
   "source": [
    "a6 = torch.tensor([                 # shape: torch.Size([3, 2, 1]), ndims(=rank): 3\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.486535Z",
     "start_time": "2023-09-19T13:12:25.412517800Z"
    }
   },
   "id": "43b17f5d26765884"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 1]) 4\n"
     ]
    }
   ],
   "source": [
    "a7 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 1]), ndims(=rank): 4\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.502538800Z",
     "start_time": "2023-09-19T13:12:25.427522400Z"
    }
   },
   "id": "a0b08e0a8245bd9d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3]) 4\n"
     ]
    }
   ],
   "source": [
    "a8 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3]), ndims(=rank): 4\n",
    "    [[[1, 2, 3], [2, 3, 4]]],\n",
    "    [[[3, 1, 1], [4, 4, 5]]],\n",
    "    [[[5, 6, 2], [6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.503538800Z",
     "start_time": "2023-09-19T13:12:25.445525500Z"
    }
   },
   "id": "920960e91260e1fa"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3, 1]) 5\n"
     ]
    }
   ],
   "source": [
    "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.543559200Z",
     "start_time": "2023-09-19T13:12:25.460529500Z"
    }
   },
   "id": "8857ffdfc8c26abb"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3, 1]) 5\n"
     ]
    }
   ],
   "source": [
    "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)\n",
    "assert a9.shape == torch.Size([3,1,2,3,1]) and a9.ndim==5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.595571Z",
     "start_time": "2023-09-19T13:12:25.472542900Z"
    }
   },
   "id": "75431a72ce31715c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 5]) 3\n"
     ]
    }
   ],
   "source": [
    "a10 = torch.tensor([                 # shape: torch.Size([4, 1, 5]), ndims(=rank): 3\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "])\n",
    "print(a10.shape, a10.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:25.624577800Z",
     "start_time": "2023-09-19T13:12:25.487535600Z"
    }
   },
   "id": "6b8f3e85fd06568f"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 3 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m a11 \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m                 \u001B[49m\u001B[38;5;66;43;03m# ValueError: expected sequence of length 3 at dim 3 (got 2)\u001B[39;49;00m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 3번째 dimension이 3이어야 했는데 [4,5]로 2개짜리 행이 있어서 ValueError\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: expected sequence of length 3 at dim 3 (got 2)"
     ]
    }
   ],
   "source": [
    "a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "])\n",
    "\n",
    "# 3번째 dimension이 3이어야 했는데 [4,5]로 2개짜리 행이 있어서 ValueError"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.588792400Z",
     "start_time": "2023-09-19T13:12:25.503538800Z"
    }
   },
   "id": "4225cad361aecbfd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "dfdf\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "122952dc11618cbd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# b_tensor_initialization_copy.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95b5cd066b168a00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.587791900Z"
    }
   },
   "id": "cd3c6eb460ee98ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l1 = [1,2,3]\n",
    "t1 = torch.Tensor(l1)\n",
    "print(l1, t1, type(l1), t1.dtype, sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.609797100Z",
     "start_time": "2023-09-19T13:12:26.591792Z"
    }
   },
   "id": "b2450c44ea13b3f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l2 = [1, 2, 3]\n",
    "t2 = torch.tensor(l2)\n",
    "\n",
    "l3 = [1, 2, 3]\n",
    "t3 = torch.as_tensor(l3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.594793300Z"
    }
   },
   "id": "cb5c1eacbfe54917"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert t1.dtype==torch.float32 and t2.dtype==torch.long\n",
    "print(t3)\n",
    "print(t3.dtype, t3.ndim, sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.598794600Z"
    }
   },
   "id": "94fccca348af8125"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#l1[0] = 100\n",
    "l2[0] = 100\n",
    "#l3[0] = 100\n",
    "print(l1, l2, l3)\n",
    "print(id(l1[0]), id(l2[0]), id(l3[0]))\n",
    "print(id(t1[0]), id(t2[0]), id(t3[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.601805400Z"
    }
   },
   "id": "77f85404996c6bc9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.605796100Z"
    }
   },
   "id": "cdd61e1621ad2f3b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### t4는 왜 dtype이 출력되지 않을까? \n",
    "torch.Tensor(list)의 경우엔 dtype=torch.float32가 출력되지 않는가 봄"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "163ff0d42a41a0f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l4 = np.array([1, 2, 3])\n",
    "t4 = torch.Tensor(l4)\n",
    "\n",
    "l5 = np.array([1, 2, 3])\n",
    "t5 = torch.tensor(l5)\n",
    "\n",
    "l6 = np.array([1, 2, 3])\n",
    "t6 = torch.as_tensor(l6)\n",
    "\n",
    "l4[0] = 100\n",
    "l5[0] = 100\n",
    "l6[0] = 100\n",
    "\n",
    "print(t4, t4.dtype)\n",
    "print(t5)\n",
    "print(t6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.608806800Z"
    }
   },
   "id": "fc1994df6c9bfeea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# c_tensor_initialization_constant_values.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cebf90e3ce93173a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.ones(size=(5,))\n",
    "t1_another = torch.ones(5)\n",
    "t1_like = torch.ones_like(t1)\n",
    "print(t1, t1_another, t1_like, sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.626799900Z",
     "start_time": "2023-09-19T13:12:26.612797300Z"
    }
   },
   "id": "5fad0d999343624"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t2 = torch.zeros(size=(5,))\n",
    "t2_another = torch.zeros([5,]) #size 매개변수로 list, tuple 등 가능\n",
    "t2_another2 = torch.zeros(5)\n",
    "t2_like = torch.zeros_like(t2)\n",
    "print(t2, t2_another, t2_another2, t2_like, sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.615808800Z"
    }
   },
   "id": "577613678b82dc72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t3 = torch.empty(size=(4,))\n",
    "t3_like = torch.empty_like(t3) # 0. 이 아니라 0에 근사한 소수가 나옴 \n",
    "t3_ano = torch.empty((4,3))\n",
    "print(t3,t3_like, t3_ano, sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.619799700Z"
    }
   },
   "id": "808b588e524b57cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eye = torch.eye(4)\n",
    "print(eye)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.622799400Z"
    }
   },
   "id": "c80725f8eccc9e80"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a1fd57b15ea148de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# d_tensor_initialization_random_values.py\n",
    "\n",
    "torch.randint(low, high, size) : return x (10<=x<20)\n",
    "torch.rand(size) :  0과 1 사이의 균등 분포 (각 소수 저마다 나올 확률이 모두 같음)\n",
    "torch.randn(size) : 0,1 사이의 표준 정규 분포 (평균 0, 표준편차 1)\n",
    "torch.normal(mean, std, size, ...) : (사용자 정의)정규분포 ---> 평균과 표준편차 직접 정의\n",
    "torch.linspace(start, end, steps, ...) : 정해진 step수 만큼 동일 간격의 수를 유지하는 1d tensor를 리턴.\n",
    "torch.arange(start=0, end, steps=1, ...) : 정해진 구간 사이의 값에 대해, start 부터 정해진 step씩 떨어진 모든 값을 1d 텐서로 반환"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e55bee66fd91e778"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t1 = torch.randint(low=10, high=20, size=(2,4))\n",
    "t2 = torch.rand(2,4)\n",
    "t3 = torch.randn(2,4)\n",
    "t4 = torch.normal(5, 1, size=(3,4))\n",
    "t5 = torch.linspace(0,4,4)\n",
    "t6 = torch.arange(1, 5, 0.5)\n",
    "print(t1, t2, t3, t4, t5, t6, sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.626799900Z"
    }
   },
   "id": "110d0fc42a44851f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.653817300Z",
     "start_time": "2023-09-19T13:12:26.629811800Z"
    }
   },
   "id": "b916ebdc4a75181e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>torch.manual_seed(seed) : random number generator를 고정된 값으로 세팅함으로써, 다음번 호출에도 똑같은 결과가 나오도록 해줄 수 있음."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52681cd4e59a60c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(1729)\n",
    "rnd1 = torch.rand(2,3)\n",
    "rnd2 = torch.rand(2,3)\n",
    "print(rnd1, rnd2, sep=\"\\n\")\n",
    "\n",
    "print( \"\\n\", \"--\"*20,  \"\\n\", \"reset\", \"\\n\")\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "rnd1_re = torch.rand(2,3)\n",
    "rnd2_re = torch.rand(2,3)\n",
    "print(rnd1_re, rnd2_re, sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.633801800Z"
    }
   },
   "id": "8d7a2878e22e5b68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.637802300Z"
    }
   },
   "id": "fbd5bda2dfff862b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# e_tensor_type_conversion.py\n",
    "\n",
    "### 주로 사용하는 torch.dtype ==> tensor.float32, int64 임.\n",
    "\n",
    "- torch.ones() 함수에 dtype 명시해주기\n",
    "- [tensor].to(dtype) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fed05b1b1ee8f1f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2,3)\n",
    "print(a, a.dtype)\n",
    "\n",
    "a_zeros = a.to(torch.int64)\n",
    "print(a_zeros)\n",
    "\n",
    "a_new = torch.ones(size=(2,3), dtype=torch.int8)\n",
    "print(a_new)\n",
    "\n",
    "a_pos = a_new.to(torch.int16)\n",
    "print(a_pos)\n",
    "\n",
    "\n",
    "print(\"\\n\", '*' * 50, \"\\n\")\n",
    "\n",
    "double_d = torch.ones(10, 2, dtype=torch.double)\n",
    "short_e = torch.tensor([[1, 2]], dtype=torch.short)\n",
    "\n",
    "double_d = torch.zeros(10, 2).double()\n",
    "short_e = torch.ones(10, 2).short()\n",
    "\n",
    "double_d = torch.zeros(10, 2).to(torch.double)\n",
    "short_e = torch.ones(10, 2).to(dtype=torch.short)\n",
    "\n",
    "double_d = torch.zeros(10, 2).type(torch.double)\n",
    "short_e = torch.ones(10, 2).type(dtype=torch.short)\n",
    "\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)\n",
    "\n",
    "double_f = torch.rand(5, dtype=torch.double) # 0,1 사이의 값으로 채워진, size 5인 double형의 tensor\n",
    "short_g = double_f.to(torch.short)\n",
    "multiply = double_f * short_g\n",
    "print(f\"double_f: {double_f}\\nshort_g: {short_g}\")\n",
    "print(multiply) # 더 큰 자료형으로 형변환 되는 듯\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.641804500Z"
    }
   },
   "id": "ad3fd748db6c5122"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# f_tensor_operations.py\n",
    "Element-wise operations : 사이즈가 같은 두 텐서끼리의 add, sub, mul, div 연산은 각 자리수끼리의 연산결과를 리턴한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb789fd76b0d5357"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t1 = torch.ones(size=(2, 3))\n",
    "t2 = torch.ones(size=(2, 3))\n",
    "t3 = torch.add(t1, t2)\n",
    "t4 = t1 + t2\n",
    "print(t3)\n",
    "print(t4)\n",
    "\n",
    "print(\"#\" * 30)\n",
    "\n",
    "t5 = torch.sub(t1, t2)\n",
    "t6 = t1 - t2\n",
    "print(t5)\n",
    "print(t6)\n",
    "\n",
    "print(\"#\" * 30)\n",
    "\n",
    "t7 = torch.mul(t1, t2)\n",
    "t8 = t1 * t2\n",
    "print(t7)\n",
    "print(t8)\n",
    "\n",
    "print(\"#\" * 30)\n",
    "\n",
    "t9 = torch.div(t1, t2)\n",
    "t10 = t1 / t2\n",
    "print(t9)\n",
    "print(t10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.644815500Z"
    }
   },
   "id": "3b116366c165be47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "************\n",
    "# g_tensor_operations_mm.py\n",
    "torch.mul(input, other): '브로드캐스팅'을 동반한 element-wise multiplications\n",
    "torch.dot(input, other) : computes the dot product of two 1D tensors\n",
    "torch.mm(input, other): matrix multiplication without 'broadcasting'\n",
    "torch.bmm(input, other): performs a batch matrix multiplication without broadcasting\n",
    "\n",
    "\n",
    "<br><br>\n",
    "##### dot 연산\n",
    "dot() 연산은 만약 A = [a₁, a₂, a₃, ..., aₙ]과 B = [b₁, b₂, b₃, ..., bₙ]이라면,\n",
    "A와 B의 도트 곱은 다음과 같이 계산됩니다:\n",
    "A · B = a₁b₁ + a₂b₂ + a₃b₃ + ... + aₙbₙ\n",
    "\n",
    "<br><br>\n",
    "##### bmm:batch에 대하여\n",
    "특별히 bmm()에 들어오는 tensor는 {batch-size X n X m}, {batch-size X m X p} 형식이어야만 한다.  \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20a41266d4ba21b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "- torch.mul() 연산에 대하여 -\n",
    "ing2 = torch.ones(size=(2,2)) * 2 로 선언했을때도 브로드캐스팅이 되어 \n",
    "ing1과 mul() 연산이 가능할 줄 알았는데 그렇지 않았다.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "ing1 = torch.rand(size=(2,4)) * 10\n",
    "ing2 = torch.ones(size=(1,4)) * 2\n",
    "#ing2 = torch.ones(size=(2,2)) * 2 # 는 mul() 불가능함\n",
    "print(ing1, ing2, sep=\"\\n\")\n",
    "\n",
    "mul_scalar = torch.mul(ing1,2)\n",
    "print(mul_scalar)\n",
    "\n",
    "mul_vec = torch.mul(ing1, ing2) # Element-wise 연산이라서, 자연히 \n",
    "print(mul_vec)\n",
    "t1 = torch.mul"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.647816100Z"
    }
   },
   "id": "4b06ceb68efe7171"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "dot()연산에 대해\n",
    "\n",
    "dot() 연산은 만약 A = [a₁, a₂, a₃, …, aₙ]과 B = [b₁, b₂, b₃, …, bₙ]이라면, A와 B의 도트 곱은 다음과 같이 계산됩니다: A · B = a₁b₁ + a₂b₂ + a₃b₃ + … + aₙbₙ\n",
    "\n",
    "broadcasting : X\n",
    "'''\n",
    "\n",
    "\n",
    "int1 = torch.arange(1,10, 2) # [1,3,5,7,9]\n",
    "int2 = torch.ones(size=(5,), dtype=torch.int64) * 2\n",
    "int_brd = torch.ones(size=(1,), dtype=torch.int64) * 2\n",
    "print(int1, int2, sep=\"\\n\")\n",
    "\n",
    "print()\n",
    "dot = torch.dot(int1, int2)\n",
    "print(dot, int1, int2, sep=\"\\n\")\n",
    "\n",
    "'''\n",
    "print(\"dot() 연산 broadcasting -test\")\n",
    "dot = torch.dot(int1, int_brd)\n",
    "print(dot, int1, int_brd, sep=\"\\n\")\n",
    "'''\n",
    "\n",
    "print(\"-\"*30)\n",
    "t1 = torch.dot(\n",
    "  torch.tensor([2, 3]), torch.tensor([2, 1])\n",
    ")\n",
    "print(t1, t1.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.651817Z"
    }
   },
   "id": "109303db3569a064"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "torch.mm() 연산은 2D Tensor끼리의 연산을 지원하며, 브로드캐스팅이 없다.\n",
    "(nXm, mXp)이면 결과로 (nXp)가 나온다. \n",
    "'''\n",
    "\n",
    "t2 = torch.randn(2, 4) # randn() 함수는 0,1 사이의 표준정규분포를 따른다.\n",
    "# t2 = torch.randn(2, 2) # 브로드캐스팅 안됌\n",
    "t3 = torch.randn(4, 2)\n",
    "t4 = torch.mm(t2, t3)\n",
    "print(t2, t3, t4, t4.size(), sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.655806800Z",
     "start_time": "2023-09-19T13:12:26.654817800Z"
    }
   },
   "id": "1b321b02282bda8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''torch.bmm()'''\n",
    "\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(10, 4, 5)\n",
    "# print(t5, t6, sep=\"\\n\")\n",
    "t7 = torch.bmm(t5, t6)\n",
    "print(t7.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.658818500Z"
    }
   },
   "id": "499f2d8fec0ba0e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# h_tensor_operations_matmul.py\n",
    "\n",
    "matmul과 mm의 차이\n",
    "\n",
    "- torch.matmul(): 이 함수는 행렬 곱셈뿐만 아니라 다양한 다차원 배열 간의 곱셈을 다룰 수 있는 범용적인 행렬 곱셈 함수입니다. 따라서 2D 행렬뿐만 아니라 고차원의 텐서에 대해서도 작동합니다. torch.matmul()은 <b>브로드캐스팅 규칙을 따르며, 고차원 텐서에 대해서도 올바르게 작동하도록 설계되었습니다.</b>\n",
    "- torch.mm(): 이 함수는 <b>오직 2D 행렬 간의 곱셈</b>만을 수행하는 함수입니다. 따라서 두 개의 2D 행렬을 인자로 받아야 하며, 두 행렬의 내적을 계산합니다. 고차원 텐서에 대해서는 작동하지 않습니다.\n",
    "\n",
    "마지막 차원의 size가 맞아야 하고, 그 두 벡터끼리 내적의 결과로 스칼라가 나오기 때문에 결과값의 차원은 마지막 차원을 뺀 나머지 차원만 남는다.\n",
    "예) matmul(5x3x4, 4) ==> (5x3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15c727bb7aceadbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# vector x vector: dot product\n",
    "t1 = torch.randn(3) # 1d\n",
    "t2 = torch.randn(3) # 1d\n",
    "print(t1, t2, t1.size())\n",
    "print()\n",
    "\n",
    "# dot 연산 확인\n",
    "cnt = torch.tensor(list(map(lambda x,y : x*y , t1,t2)))\n",
    "res = sum(cnt) \n",
    "print(f'cnt: {cnt}, res: {res}')\n",
    "\n",
    "print(torch.matmul(t1, t2))\n",
    "print(torch.matmul(t1, t2).size())  # torch.Size([])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.661808600Z"
    }
   },
   "id": "19b1dea26252fe6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# matrix x vector: broadcasted dot\n",
    "t3 = torch.randn(3, 4)\n",
    "# t4 = torch.randn(3) # 이렇게는 브로드캐스팅 안됌. 마지막 차원에 맞춰야 하는 듯\n",
    "t4 = torch.randn(4)\n",
    "print(t3, t4, sep=\"\\n\")\n",
    "print(torch.matmul(t3,t4))\n",
    "print(torch.matmul(t3, t4).size())  # torch.Size([3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.700819700Z",
     "start_time": "2023-09-19T13:12:26.665810Z"
    }
   },
   "id": "62a30d104f59a31f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# batched matrix x vector: broadcasted dot\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(4)\n",
    "# t6 = torch.randn(3,4) # Error\n",
    "# t6 = torch.randn(4,5) # OK\n",
    "print(torch.matmul(t5, t6).size())  # torch.Size([10, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.669810700Z"
    }
   },
   "id": "61409d78ed08693b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# batched matrix x batched matrix: bmm\n",
    "t7 = torch.randn(10, 3, 4)\n",
    "t8 = torch.randn(10, 4, 5)\n",
    "print(torch.matmul(t7, t8).size())  # torch.Size([10, 3, 5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.673812900Z"
    }
   },
   "id": "a885eaf2076e9672"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# batched matrix x matrix: bmm\n",
    "t9 = torch.randn(10, 3, 4)\n",
    "t10 = torch.randn(4, 5)\n",
    "print(torch.matmul(t9, t10).size())  # torch.Size([10, 3, 5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.676812400Z"
    }
   },
   "id": "fe0be9c39d361d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# i_tensor_broadcasting.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c98206c954999cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1 * t2)\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
    "t4 = torch.tensor([4, 5])\n",
    "print(t3 - t4)\n",
    "\n",
    "print(\"#\" * 50, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.680823700Z"
    }
   },
   "id": "40aa18e9592ee083"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t5 = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t5 + 2.0)  # t5.add(2.0)\n",
    "print(t5 - 2.0)  # t5.sub(2.0)\n",
    "print(t5 * 2.0)  # t5.mul(2.0)\n",
    "print(t5 / 2.0)  # t5.div(2.0)\n",
    "\n",
    "print(\"#\" * 50, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.683813500Z"
    }
   },
   "id": "401343009f5fe00b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "  return x / 255\n",
    "\n",
    "\n",
    "t6 = torch.randn(3, 28, 28)\n",
    "print(normalize(t6).size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.686814300Z"
    }
   },
   "id": "6755ab6613bdec5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 4)\n",
    "\n",
    "t7 = torch.tensor([[1, 2], [0, 3]])  # torch.Size([2, 2])\n",
    "t8 = torch.tensor([[3, 1]])  # torch.Size([1, 2])\n",
    "t9 = torch.tensor([[5], [2]])  # torch.Size([2, 1])\n",
    "t10 = torch.tensor([7])  # torch.Size([1])\n",
    "print(t7 + t8)   # >>> tensor([[4, 3], [3, 4]])\n",
    "print(t7 + t9)   # >>> tensor([[6, 7], [2, 5]])\n",
    "print(t8 + t9)   # >>> tensor([[8, 6], [5, 3]])\n",
    "print(t7 + t10)  # >>> tensor([[ 8, 9], [ 7, 10]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.688825600Z"
    }
   },
   "id": "3141d74ade3c0ee1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "4칙연산 연산에 대해서는 broadcasting (o) \n",
    "단, 동일 차원의 맞지 않는 사이즈가 서로 배수관계여야 한다\n",
    "'''\n",
    "\n",
    "print(\"#\" * 50, 5)\n",
    "\n",
    "t11 = torch.ones(4, 3, 2)\n",
    "t12 = t11 * torch.rand(3, 2)  # 3rd & 2nd dims identical to t11, dim 0 absent\n",
    "print(t12.shape)\n",
    "\n",
    "t13 = torch.ones(4, 3, 2)\n",
    "t14 = t13 * torch.rand(3, 1)  # 3rd dim = 1, 2nd dim is identical to t13\n",
    "print(t14.shape)\n",
    "\n",
    "t15 = torch.ones(4, 3, 2)\n",
    "t16 = t15 * torch.rand(1, 2)  # 3rd dim is identical to t15, 2nd dim is 1\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.ones(5, 3, 4, 1)\n",
    "t18 = torch.rand(3, 1, 1)  # 2nd dim is identical to t17, 3rd and 4th dims are 1\n",
    "print((t17 + t18).size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.691815100Z"
    }
   },
   "id": "a1f6e3a1594a8f19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 6)\n",
    "\n",
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 = torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size())  # torch.Size([5, 3, 4, 1])\n",
    "\n",
    "t21 = torch.empty(1)\n",
    "t22 = torch.empty(3, 1, 7)\n",
    "print((t21 + t22).size())  # torch.Size([3, 1, 7])\n",
    "\n",
    "t23 = torch.ones(3, 3, 3)\n",
    "t24 = torch.ones(3, 1, 3)\n",
    "print((t23 + t24).size())  # torch.Size([3, 3, 3])\n",
    "\n",
    "# t25 = torch.empty(5, 2, 4, 1)\n",
    "# t26 = torch.empty(3, 1, 1)\n",
    "# print((t25 + t26).size())\n",
    "# RuntimeError: The size of tensor a (2) must match\n",
    "# the size of tensor b (3) at non-singleton dimension 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.693817500Z"
    }
   },
   "id": "e5d528eefc595060"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 7)\n",
    "\n",
    "t27 = torch.ones(4) * 5\n",
    "print(t27)  # >>> tensor([ 5, 5, 5, 5])\n",
    "\n",
    "t28 = torch.pow(t27, 2)\n",
    "print(t28)  # >>> tensor([ 25, 25, 25, 25])\n",
    "\n",
    "exp = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
    "a = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
    "t29 = torch.pow(a, exp)\n",
    "print(t29)  # >>> tensor([   1.,    4.,   27.,  256.])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.696819600Z"
    }
   },
   "id": "9f96e355f781aa36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# j_tensor_indexing_slicing.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e29c2da8d2afa33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9],\n",
    "   [10, 11, 12, 13, 14]]\n",
    ") # size= (3,5)\n",
    "\n",
    "print(x[1])  # >>> tensor([5, 6, 7, 8, 9])\n",
    "print(x[:, 1])  # >>> tensor([1, 6, 11])\n",
    "print(x[1, 2])  # >>> tensor(7)\n",
    "print(x[:, -1])  # >>> tensor([4, 9, 14)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.699818500Z"
    }
   },
   "id": "2e3a5d152540b4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 1)\n",
    "\n",
    "print(x[1:])  # >>> tensor([[ 5,  6,  7,  8,  9], [10, 11, 12, 13, 14]])\n",
    "print(x[1:, 3:])  # >>> tensor([[ 8,  9], [13, 14]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.702819500Z",
     "start_time": "2023-09-19T13:12:26.701820700Z"
    }
   },
   "id": "6d4190b60c55e5c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 2)\n",
    "\n",
    "y = torch.zeros((6, 6))\n",
    "y[1:4, 2] = 1\n",
    "print(y)\n",
    "\n",
    "print(y[1:4, 1:4])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.704820600Z"
    }
   },
   "id": "1d52310a0094a4d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 3)\n",
    "\n",
    "z = torch.tensor(\n",
    "  [[1, 2, 3, 4],\n",
    "   [2, 3, 4, 5],\n",
    "   [5, 6, 7, 8]]\n",
    ")\n",
    "print(z[:2]) #tensor([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "print(z[1:, 1:3]) #\n",
    "print(z[:, 1:])\n",
    "\n",
    "z[1:, 1:3] = 0\n",
    "print(z)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.706821600Z"
    }
   },
   "id": "20caf3a5696b9d77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# k_tensor_reshaping.py\n",
    "\n",
    "torch.tensor.view(size=(..))\n",
    "torch.tensor.reshape(size=(..))\n",
    "\n",
    "squeeze() : tensor의 모든 1차원 데이터를 flatten() 시킴\n",
    "    즉, 1차원이 없도록 만듦.\n",
    "    - squeeze(dim=N) : 특정 차원의 dimension이 1이면 차원 삭제 \n",
    "    \n",
    "unsqueeze(dim) : 특정 위치의 차원을 한번 감쌈 (squeeze의 반대) \n",
    "\n",
    "flatten() : 1차원 텐서로 만듦\n",
    "    - torch.flatten(tensor, start_dim=#)\n",
    "        start_dim = 이 인덱스를 기점으로 하위 차원의 값들을 flatten\n",
    "\n",
    "permute() : 다차원 텐서의 차원을 일일히 지정하여 바꾸는 것\n",
    "\n",
    "transpose(): 행과 열을 입력받아 두 차원을 바꿔주는 함수\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8cb8146b4d14ef0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = t1.view(3, 2)  # Shape becomes (3, 2)\n",
    "t3 = t1.reshape(1, 6)  # Shape becomes (1, 6)\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.arange(8).view(2, 4)  # Shape becomes (2, 4)\n",
    "t5 = torch.arange(6).view(2, 3)  # Shape becomes (2, 3)\n",
    "print(t4)\n",
    "print(t5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.723824500Z",
     "start_time": "2023-09-19T13:12:26.709821400Z"
    }
   },
   "id": "5633b95810206a80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 1)\n",
    "\n",
    "# Original tensor with shape (1, 3, 1)\n",
    "t6 = torch.tensor([[[1], [2], [3]]])\n",
    "\n",
    "# Remove all dimensions of size 1\n",
    "t7 = t6.squeeze()  # Shape becomes (3,)\n",
    "\n",
    "# Remove dimension at position 0\n",
    "t8 = t6.squeeze(0)  # Shape becomes (3, 1)\n",
    "print(t7)\n",
    "print(t8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.711821600Z"
    }
   },
   "id": "379c4353585308c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 2)\n",
    "\n",
    "# Original tensor with shape (3,)\n",
    "t9 = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Add a new dimension at position 1\n",
    "t10 = t9.unsqueeze(1)  # Shape becomes (3, 1)\n",
    "print(t10)\n",
    "\n",
    "t11 = torch.tensor(\n",
    "  [[1, 2, 3],\n",
    "   [4, 5, 6]]\n",
    ")\n",
    "t12 = t11.unsqueeze(1)  # Shape becomes (2, 1, 3)\n",
    "print(t12, t12.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.714822800Z"
    }
   },
   "id": "300b10c4689e9920"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 3)\n",
    "\n",
    "# Original tensor with shape (2, 3)\n",
    "t13 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Flatten the tensor\n",
    "t14 = t13.flatten()  # Shape becomes (6,)\n",
    "\n",
    "print(t14)\n",
    "\n",
    "# Original tensor with shape (2, 2, 2)\n",
    "t15 = torch.tensor([[[1, 2],\n",
    "                     [3, 4]],\n",
    "                    [[5, 6],\n",
    "                     [7, 8]]])\n",
    "t16 = torch.flatten(t15)\n",
    "\n",
    "t17 = torch.flatten(t15, start_dim=1)\n",
    "\n",
    "print(t16)\n",
    "print(t17)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.716823900Z"
    }
   },
   "id": "3e60a1cf5e3507d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 4)\n",
    "\n",
    "t18 = torch.randn(2, 3, 5)\n",
    "print(t18.shape)  # >>> torch.Size([2, 3, 5])\n",
    "print(torch.permute(t18, (2, 0, 1)).size())  # >>> torch.Size([5, 2, 3])\n",
    "\n",
    "# Original tensor with shape (2, 3)\n",
    "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Permute the dimensions\n",
    "t20 = torch.permute(t19, dims=(0, 1))  # Shape becomes (2, 3) still\n",
    "t21 = torch.permute(t19, dims=(1, 0))  # Shape becomes (3, 2)\n",
    "print(t20)\n",
    "print(t21)\n",
    "\n",
    "# Transpose the tensor\n",
    "t22 = torch.transpose(t19, 0, 1)  # Shape becomes (3, 2)\n",
    "\n",
    "print(t22)\n",
    "\n",
    "t23 = torch.t(t19)  # Shape becomes (3, 2)\n",
    "\n",
    "print(t23)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.719823300Z"
    }
   },
   "id": "4ad3249a893292b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# l_tensor_concat.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f4f04a03b1db43f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.zeros([2, 3, 3])\n",
    "t3 = torch.zeros([2, 2, 3])\n",
    "\n",
    "t4 = torch.cat([t1, t2, t3], dim=1)\n",
    "print(t4.shape) # torch.Size([2, 6, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.721824900Z"
    }
   },
   "id": "58e4b76d4456ba3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t5 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t6 = torch.arange(3, 8)  # tensor([3, 4, 5, 6, 7])\n",
    "\n",
    "t7 = torch.cat((t5, t6), dim=0)\n",
    "print(t7.shape)  # >>> torch.Size([8])\n",
    "print(t7)  # >>> tensor([0, 1, 2, 3, 4, 5, 6, 7])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:12:26.851852900Z",
     "start_time": "2023-09-19T13:12:26.724824600Z"
    }
   },
   "id": "5edc9b8f5271553d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 2)\n",
    "\n",
    "t8 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t9 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "# 2차원 텐서간 병합\n",
    "t10 = torch.cat((t8, t9), dim=0)\n",
    "print(t10.size())  # >>> torch.Size([4, 3])\n",
    "print(t10)\n",
    "# >>> tensor([[ 0,  1,  2],\n",
    "#             [ 3,  4,  5],\n",
    "#             [ 6,  7,  8],\n",
    "#             [ 9, 10, 11]])\n",
    "\n",
    "t11 = torch.cat((t8, t9), dim=1)\n",
    "print(t11.size())  # >>>torch.Size([2, 6])\n",
    "print(t11)\n",
    "# >>> tensor([[ 0,  1,  2,  6,  7,  8],\n",
    "#             [ 3,  4,  5,  9, 10, 11]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.726825600Z"
    }
   },
   "id": "bc63b6732a49e05d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 3)\n",
    "\n",
    "t12 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t13 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t14 = torch.arange(12, 18).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "t15 = torch.cat((t12, t13, t14), dim=0)\n",
    "print(t15.size())  # >>> torch.Size([6, 3])\n",
    "print(t15)\n",
    "# >>> tensor([[ 0,  1,  2],\n",
    "#             [ 3,  4,  5],\n",
    "#             [ 6,  7,  8],\n",
    "#             [ 9, 10, 11],\n",
    "#             [12, 13, 14],\n",
    "#             [15, 16, 17]])\n",
    "\n",
    "t16 = torch.cat((t12, t13, t14), dim=1)\n",
    "print(t16.size())  # >>> torch.Size([2, 9])\n",
    "print(t16)\n",
    "# >>> tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
    "#             [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.729825900Z"
    }
   },
   "id": "4f3414cf217ede0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 4)\n",
    "\n",
    "t17 = torch.arange(0, 6).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "t18 = torch.arange(6, 12).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "\n",
    "t19 = torch.cat((t17, t18), dim=0)\n",
    "print(t19.size())  # >>> torch.Size([2, 2, 3])\n",
    "print(t19)\n",
    "# >>> tensor([[[ 0,  1,  2],\n",
    "#              [ 3,  4,  5]],\n",
    "#             [[ 6,  7,  8],\n",
    "#              [ 9, 10, 11]]])\n",
    "\n",
    "t20 = torch.cat((t17, t18), dim=1)\n",
    "print(t20.size())  # >>> torch.Size([1, 4, 3])\n",
    "print(t20)\n",
    "# >>> tensor([[[ 0,  1,  2],\n",
    "#              [ 3,  4,  5],\n",
    "#              [ 6,  7,  8],\n",
    "#              [ 9, 10, 11]]])\n",
    "\n",
    "t21 = torch.cat((t17, t18), dim=2)\n",
    "print(t21.size())  # >>> torch.Size([1, 2, 6])\n",
    "print(t21)\n",
    "# >>> tensor([[[ 0,  1,  2,  6,  7,  8],\n",
    "#              [ 3,  4,  5,  9, 10, 11]]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.731826600Z"
    }
   },
   "id": "fb773d1059a4d37b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# m_tensor_stacking.py\n",
    "torch.stack()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcbef2c59cb5f2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]]) # 2, 3\n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]]) # 2, 3\n",
    "\n",
    "t3 = torch.stack([t1, t2], dim=0)\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0) # 2,2,3\n",
    "# cat((1,2,3), (1,2,3), dim=0) ==> (2,2,3)\n",
    "print(t3.shape, t3.equal(t4))\n",
    "\n",
    "t5 = torch.stack([t1, t2], dim=1)\n",
    "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1)\n",
    "# cat((2, 1, 3), (2, 1, 3), dim=1) ==> (2,2,3)\n",
    "print(t5.shape, t5.equal(t6))\n",
    "\n",
    "t7 = torch.stack([t1, t2], dim=2)\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2)\n",
    "# cat((2,3,1), (2,3,1), dim=2)\n",
    "print(t7.shape, t7.equal(t8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.733826800Z"
    }
   },
   "id": "bd75513d14636174"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t9 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t10 = torch.arange(3, 6)  # tensor([3, 4, 5])\n",
    "\n",
    "print(t9.size(), t10.size())\n",
    "# >>> torch.Size([3]) torch.Size([3])\n",
    "\n",
    "t11 = torch.stack((t9, t10), dim=0)\n",
    "print(t11.size())  # >>> torch.Size([2,3])\n",
    "print(t11)\n",
    "# >>> tensor([[0, 1, 2],\n",
    "#             [3, 4, 5]])\n",
    "\n",
    "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0)\n",
    "print(t11.equal(t12))\n",
    "# >>> True\n",
    "\n",
    "t13 = torch.stack((t9, t10), dim=1)\n",
    "print(t13.size())  # >>> torch.Size([3,2])\n",
    "print(t13)\n",
    "# >>> tensor([[0, 3],\n",
    "#             [1, 4],\n",
    "#             [2, 5]])\n",
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1)\n",
    "print(t13.equal(t14))\n",
    "# >>> True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.736827300Z"
    }
   },
   "id": "43ae4a405f8172b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# n_tensor_vstack_hstack.py \n",
    "\n",
    "virtical VS horizontal\n",
    "\n",
    "vstack : 최상위차원에 스택을 쌓는 느낌 \n",
    "hstack : 상위 2번째 차원에 스택을 쌓는 느낌 ==> 모든 텐서가 동일한 행의 개수를 가져야함\n",
    "(인자로 list 형식도 가능함)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fe36cac5d1b5d89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([1,2,3])\n",
    "t2 = torch.tensor([4,5,6])\n",
    "t3 = torch.vstack((t1,t2))\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.tensor([[1],[2],[3]]) # 3,1\n",
    "t5 = torch.tensor([[4],[5],[6]]) # 3,1\n",
    "t6 = torch.vstack((t4,t5))\n",
    "print(t6)\n",
    "t6 = torch.vstack([t4,t5])\n",
    "print(t6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.738827900Z"
    }
   },
   "id": "e461d0a389bb89b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t7 = torch.tensor ([\n",
    "[[1, 2, 3], [4, 5, 6]],\n",
    "[[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "\n",
    "print(t7.shape)\n",
    "\n",
    "t8 = torch.tensor([\n",
    "[[13, 14, 15], [16, 17, 18]],\n",
    "[[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t8.shape)\n",
    "# >>> (2, 2, 3)\n",
    "\n",
    "t9 = torch.vstack ([t7, t8])\n",
    "print(t9.shape)\n",
    "# >>> (4, 2, 3)\n",
    "print(t9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.741828700Z"
    }
   },
   "id": "874251a4d385cd96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "t10 = torch.tensor([1, 2, 3])\n",
    "t11 = torch.tensor([4, 5, 6])\n",
    "t12 = torch.hstack((t10, t11))\n",
    "print(t12)\n",
    "# >>> tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "t13 = torch.tensor([[1], [2], [3]])\n",
    "t14 = torch.tensor([[4], [5], [6]])\n",
    "t15 = torch.hstack((t13, t14)) # 3, 2\n",
    "print(t15)\n",
    "# >>> tensor([[1, 4],\n",
    "# [2, 5],\n",
    "# [3, 6]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.743829100Z"
    }
   },
   "id": "7c430b28cb8eb7de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t16 = torch.tensor([\n",
    "[[1, 2, 3], [4, 5, 6]],\n",
    "[[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t16.shape)\n",
    "# >>> (2, 2, 3)\n",
    "\n",
    "t17 = torch.tensor([\n",
    "[[13, 14, 15], [16, 17, 18]],\n",
    "[[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t17.shape)\n",
    "# >>> (2, 2, 3)\n",
    "\n",
    "t18 = torch.hstack([t16, t17])\n",
    "print(t18.shape)\n",
    "# >>> (2, 4, 3)\n",
    "\n",
    "print(t18)\n",
    "# >>> tensor([[[ 1, 2, 3],\n",
    "# [ 4, 5, 6],\n",
    "# [13, 14, 15],\n",
    "# [16, 17, 18]],\n",
    "# [[ 7, 8, 9],\n",
    "# [10, 11, 12],\n",
    "# [19, 20, 21],\n",
    "# [22, 23, 24]]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.745829600Z"
    }
   },
   "id": "3b813818fa555fe3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m1 = torch.zeros([3,4,5,2])\n",
    "m2 = torch.zeros([3,4,5,2])\n",
    "res = torch.hstack([m1,m2])\n",
    "print(res.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-19T13:12:26.748830300Z"
    }
   },
   "id": "a2f1628008389e8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----------------------------------\n",
    "# 숙제 후기\n",
    "\n",
    "전에 numpy를 배운 적이 있지만 다 까먹었다. 교수님께서 numpy와 tensor가 비슷한 측면이 많다고 하셨는데, 여러모로 그런거 같다고 느꼈다. \n",
    "\n",
    "확실히 행렬이 들어가면서 선형대수학 시간에 배웠던 것들이 많이 보였다. 덕분에 과제를 수행하면서 내적과 외적의 의미를 다시한번 찾아보고 복습하는 계기가 되었다.\n",
    "\n",
    "교수님께서 우리를 가르치실 때 이 많은 함수들을 모두 다 외우라고 시키시기 보다는 어떤 함수가 중요한 함수이고 어떤 부분이 중요한지를 짚어주셔서 공부하기에 한참 수월한 느낌을 받았다. \n",
    "\n",
    "비록 코드를 다 주셨지만 일일히 따라 쳐보면서 공부했더니 도움이 많이 되었다. \n",
    "예를 들어 size를 tuple로 넘겨주는 코드를 주로 보다가 \n",
    "<code>torch.tensor([1,2,3])</code>\n",
    " 같은 것을 보니 Size(3,) 짜리 텐서가 아닌 Size(1,2,3) 짜리 텐서로 생각하는 등의 헤프닝이 있었다.\n",
    "\n",
    "하지만, 역설적이게도, 사실 나는 무작정 따라 치기보다는 머리로 이해하는 과정이 더욱 중요하다고 생각한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c595c42116971212"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
