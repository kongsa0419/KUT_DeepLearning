{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61321a42a27b7b3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 과목명: 딥러닝및실습 hw1_1\n",
    "##### 실습자: 2017136063 여승준"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa02ea265d832dc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# a_tensor_initialization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "702351db80b62eee",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:07.813456900Z",
     "start_time": "2023-09-19T13:22:07.412365300Z"
    }
   },
   "outputs": [],
   "source": [
    "#pytorch's main package which is a tensor library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c037e86967c3c40",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:08.518409400Z",
     "start_time": "2023-09-19T13:22:07.423367700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.Tensor([1,2,3], device='cpu')\n",
    "'''\n",
    "torch.'T'ensor = torch.FloatTensor이고,\n",
    "torch.'t'ensor = torch.LongTensor임. (생성자)\n",
    "\n",
    "미분에 관한 연산엔진을 내장하는 \n",
    "requires_grad 옵션은 , default = False\n",
    "'''\n",
    "print(t1.dtype)         # torch.float32\n",
    "print(t1.device)        # >>> cpu\n",
    "print(t1.requires_grad) # >>>False\n",
    "print(t1.size())        # torch.Size([3])\n",
    "print(t1.shape)         # torch.Size([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21ef62fb8dd636a3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:08.672445Z",
     "start_time": "2023-09-19T13:22:07.433369900Z"
    }
   },
   "outputs": [],
   "source": [
    "# if you have gpu device\n",
    "# t1_cuda = t1.to(torch.device('cuda')) #>>> error for me\n",
    "\n",
    "# or you can use shorthand (내 컴퓨터의 경우 t1.cuda()가 먹지 않았다.)\n",
    "#t1_cuda = t1.cuda()\n",
    "t1_cpu = t1.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c67746ec04f942fc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:08.699196900Z",
     "start_time": "2023-09-19T13:22:07.449373800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 1\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9345cf4bbf420fe",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:08.799377900Z",
     "start_time": "2023-09-19T13:22:07.467377500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor function\n",
    "t2 = torch.tensor([1,2,3], device='cpu')\n",
    "print(t2.dtype) \n",
    "print(t2.device)\n",
    "print(t2.requires_grad)\n",
    "print(t2.size())\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6588a5b574dbdc4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:08.838386800Z",
     "start_time": "2023-09-19T13:22:07.481380300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 2\n"
     ]
    }
   ],
   "source": [
    "# if you have gpu device\n",
    "# t2_cuda = t2.to(torch.device('cuda'))\n",
    "# or you can use shorthand\n",
    "# t2_cuda = t2.cuda()\n",
    "t2_cpu = t2.cpu()\n",
    "\n",
    "print(\"#\" * 50, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e00b965c14b4db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 텐서의 shape(=size)를 구하는 법, dimension을 구할 줄 알아야 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69ae7faf97992a86",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:08.884399200Z",
     "start_time": "2023-09-19T13:22:07.497384300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1)\t\t\t     # shape: torch.Size([]), ndims(=rank): 0\n",
    "print(a1.shape, a1.ndim)\n",
    "assert a1.shape == torch.Size([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d224692b506edec",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:08.920407500Z",
     "start_time": "2023-09-19T13:22:07.514388600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) 1\n",
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "a2 = torch.tensor([1])\t\t  \t     # shape: torch.Size([1]), ndims(=rank): 1\n",
    "print(a2.shape, a2.ndim)\n",
    "print(a2.dtype)\n",
    "assert a2.dtype == torch.int64\n",
    "\n",
    "a2_float = torch.as_tensor(a2, dtype=torch.float)\n",
    "print(a2_float.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85e4beeb061941f3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:08.994423800Z",
     "start_time": "2023-09-19T13:22:07.527391100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) 1\n"
     ]
    }
   ],
   "source": [
    "a3 = torch.tensor([1, 2, 3, 4, 5])   # shape: torch.Size([5]), ndims(=rank): 1\n",
    "print(a3.shape, a3.ndim)\n",
    "assert a3.shape==torch.Size([5])\n",
    "assert a3.ndim == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88894deae1137f1e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.104439Z",
     "start_time": "2023-09-19T13:22:07.543394700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1]) 2\n"
     ]
    }
   ],
   "source": [
    "a4 = torch.tensor([[1], [2], [3], [4], [5]])   # shape: torch.Size([5, 1]), ndims(=rank): 2\n",
    "print(a4.shape, a4.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14022ea7cba10dd2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.344494600Z",
     "start_time": "2023-09-19T13:22:07.561399600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) 2\n"
     ]
    }
   ],
   "source": [
    "a5 = torch.tensor([                 # shape: torch.Size([3, 2]), ndims(=rank): 2\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43b17f5d26765884",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.454529300Z",
     "start_time": "2023-09-19T13:22:07.577402600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 1]) 3\n"
     ]
    }
   ],
   "source": [
    "a6 = torch.tensor([                 # shape: torch.Size([3, 2, 1]), ndims(=rank): 3\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0b08e0a8245bd9d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.575549200Z",
     "start_time": "2023-09-19T13:22:07.593407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 1]) 4\n"
     ]
    }
   ],
   "source": [
    "a7 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 1]), ndims(=rank): 4\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "920960e91260e1fa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.721135400Z",
     "start_time": "2023-09-19T13:22:07.614411300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3]) 4\n"
     ]
    }
   ],
   "source": [
    "a8 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3]), ndims(=rank): 4\n",
    "    [[[1, 2, 3], [2, 3, 4]]],\n",
    "    [[[3, 1, 1], [4, 4, 5]]],\n",
    "    [[[5, 6, 2], [6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8857ffdfc8c26abb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.736147300Z",
     "start_time": "2023-09-19T13:22:07.623423900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3, 1]) 5\n"
     ]
    }
   ],
   "source": [
    "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75431a72ce31715c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.736147300Z",
     "start_time": "2023-09-19T13:22:07.639427800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3, 1]) 5\n"
     ]
    }
   ],
   "source": [
    "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)\n",
    "assert a9.shape == torch.Size([3,1,2,3,1]) and a9.ndim==5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b8f3e85fd06568f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.737138500Z",
     "start_time": "2023-09-19T13:22:07.658421600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 5]) 3\n"
     ]
    }
   ],
   "source": [
    "a10 = torch.tensor([                 # shape: torch.Size([4, 1, 5]), ndims(=rank): 3\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "])\n",
    "print(a10.shape, a10.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4225cad361aecbfd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.737138500Z",
     "start_time": "2023-09-19T13:22:07.673425100Z"
    }
   },
   "outputs": [],
   "source": [
    "# a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
    "#     [[[1, 2, 3], [4, 5]]],\n",
    "#     [[[1, 2, 3], [4, 5]]],\n",
    "#     [[[1, 2, 3], [4, 5]]],\n",
    "#     [[[1, 2, 3], [4, 5]]],\n",
    "# ])\n",
    "\n",
    "# 3번째 dimension이 3이어야 했는데 [4,5]로 2개짜리 행이 있어서 ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122952dc11618cbd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "dfdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5cd066b168a00",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# b_tensor_initialization_copy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd3c6eb460ee98ed",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.738150400Z",
     "start_time": "2023-09-19T13:22:07.687439Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2450c44ea13b3f3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.738150400Z",
     "start_time": "2023-09-19T13:22:07.705433300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "tensor([1., 2., 3.])\n",
      "<class 'list'>\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "l1 = [1,2,3]\n",
    "t1 = torch.Tensor(l1)\n",
    "print(l1, t1, type(l1), t1.dtype, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb5c1eacbfe54917",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.738150400Z",
     "start_time": "2023-09-19T13:22:07.721437Z"
    }
   },
   "outputs": [],
   "source": [
    "l2 = [1, 2, 3]\n",
    "t2 = torch.tensor(l2)\n",
    "\n",
    "l3 = [1, 2, 3]\n",
    "t3 = torch.as_tensor(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94fccca348af8125",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.738150400Z",
     "start_time": "2023-09-19T13:22:07.735450300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.int64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "assert t1.dtype==torch.float32 and t2.dtype==torch.long\n",
    "print(t3)\n",
    "print(t3.dtype, t3.ndim, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77f85404996c6bc9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.738150400Z",
     "start_time": "2023-09-19T13:22:07.752443100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] [100, 2, 3] [1, 2, 3]\n",
      "2723154493680 2723154496848 2723154493680\n",
      "2723898701072 2723233919632 2723233919632\n"
     ]
    }
   ],
   "source": [
    "#l1[0] = 100\n",
    "l2[0] = 100\n",
    "#l3[0] = 100\n",
    "print(l1, l2, l3)\n",
    "print(id(l1[0]), id(l2[0]), id(l3[0]))\n",
    "print(id(t1[0]), id(t2[0]), id(t3[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdd61e1621ad2f3b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.742141100Z",
     "start_time": "2023-09-19T13:22:07.769447900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ff0d42a41a0f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### t4는 왜 dtype이 출력되지 않을까? \n",
    "torch.Tensor(list)의 경우엔 dtype=torch.float32가 출력되지 않는가 봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc1994df6c9bfeea",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.742141100Z",
     "start_time": "2023-09-19T13:22:07.788451400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.]) torch.float32\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([100,   2,   3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "l4 = np.array([1, 2, 3])\n",
    "t4 = torch.Tensor(l4)\n",
    "\n",
    "l5 = np.array([1, 2, 3])\n",
    "t5 = torch.tensor(l5)\n",
    "\n",
    "l6 = np.array([1, 2, 3])\n",
    "t6 = torch.as_tensor(l6)\n",
    "\n",
    "l4[0] = 100\n",
    "l5[0] = 100\n",
    "l6[0] = 100\n",
    "\n",
    "print(t4, t4.dtype)\n",
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebf90e3ce93173a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# c_tensor_initialization_constant_values.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5fad0d999343624",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.746141200Z",
     "start_time": "2023-09-19T13:22:07.802455800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.ones(size=(5,))\n",
    "t1_another = torch.ones(5)\n",
    "t1_like = torch.ones_like(t1)\n",
    "print(t1, t1_another, t1_like, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "577613678b82dc72",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.747151900Z",
     "start_time": "2023-09-19T13:22:07.816457800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.zeros(size=(5,))\n",
    "t2_another = torch.zeros([5,]) #size 매개변수로 list, tuple 등 가능\n",
    "t2_another2 = torch.zeros(5)\n",
    "t2_like = torch.zeros_like(t2)\n",
    "print(t2, t2_another, t2_another2, t2_like, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "808b588e524b57cf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.747151900Z",
     "start_time": "2023-09-19T13:22:07.833461600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0.])\n",
      "tensor([3.5873e-43,        nan, 3.2973e-04, 4.5909e-41])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.empty(size=(4,))\n",
    "t3_like = torch.empty_like(t3) # 0. 이 아니라 0에 근사한 소수가 나옴 \n",
    "t3_ano = torch.empty((4,3))\n",
    "print(t3,t3_like, t3_ano, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c80725f8eccc9e80",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.747151900Z",
     "start_time": "2023-09-19T13:22:07.849465600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "eye = torch.eye(4)\n",
    "print(eye)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd57b15ea148de",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e55bee66fd91e778",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# d_tensor_initialization_random_values.py\n",
    "\n",
    "torch.randint(low, high, size) : return x (10<=x<20)\n",
    "torch.rand(size) :  0과 1 사이의 균등 분포 (각 소수 저마다 나올 확률이 모두 같음)\n",
    "torch.randn(size) : 0,1 사이의 표준 정규 분포 (평균 0, 표준편차 1)\n",
    "torch.normal(mean, std, size, ...) : (사용자 정의)정규분포 ---> 평균과 표준편차 직접 정의\n",
    "torch.linspace(start, end, steps, ...) : 정해진 step수 만큼 동일 간격의 수를 유지하는 1d tensor를 리턴.\n",
    "torch.arange(start=0, end, steps=1, ...) : 정해진 구간 사이의 값에 대해, start 부터 정해진 step씩 떨어진 모든 값을 1d 텐서로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "110d0fc42a44851f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.747151900Z",
     "start_time": "2023-09-19T13:22:07.865469700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17, 10, 11, 10],\n",
      "        [11, 16, 17, 15]])\n",
      "tensor([[0.4185, 0.5007, 0.6236, 0.7559],\n",
      "        [0.3635, 0.3987, 0.5057, 0.7642]])\n",
      "tensor([[ 0.6856,  0.4161, -2.7180, -0.8691],\n",
      "        [-0.8015, -0.3534, -0.9983, -0.3400]])\n",
      "tensor([[3.2105, 4.1356, 5.6637, 4.9325],\n",
      "        [4.2455, 5.2857, 5.2271, 3.6281],\n",
      "        [4.9551, 6.4487, 5.8539, 3.0533]])\n",
      "tensor([0.0000, 1.3333, 2.6667, 4.0000])\n",
      "tensor([1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000, 4.5000])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randint(low=10, high=20, size=(2,4))\n",
    "t2 = torch.rand(2,4)\n",
    "t3 = torch.randn(2,4)\n",
    "t4 = torch.normal(5, 1, size=(3,4))\n",
    "t5 = torch.linspace(0,4,4)\n",
    "t6 = torch.arange(1, 5, 0.5)\n",
    "print(t1, t2, t3, t4, t5, t6, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b916ebdc4a75181e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.749141100Z",
     "start_time": "2023-09-19T13:22:07.877471800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52681cd4e59a60c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<b>torch.manual_seed(seed) : random number generator를 고정된 값으로 세팅함으로써, 다음번 호출에도 똑같은 결과가 나오도록 해줄 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d7a2878e22e5b68",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.749141100Z",
     "start_time": "2023-09-19T13:22:07.893475500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "\n",
      " ---------------------------------------- \n",
      " reset \n",
      "\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "rnd1 = torch.rand(2,3)\n",
    "rnd2 = torch.rand(2,3)\n",
    "print(rnd1, rnd2, sep=\"\\n\")\n",
    "\n",
    "print( \"\\n\", \"--\"*20,  \"\\n\", \"reset\", \"\\n\")\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "rnd1_re = torch.rand(2,3)\n",
    "rnd2_re = torch.rand(2,3)\n",
    "print(rnd1_re, rnd2_re, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbd5bda2dfff862b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.749141100Z",
     "start_time": "2023-09-19T13:22:07.924484Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed05b1b1ee8f1f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# e_tensor_type_conversion.py\n",
    "\n",
    "### 주로 사용하는 torch.dtype ==> tensor.float32, int64 임.\n",
    "\n",
    "- torch.ones() 함수에 dtype 명시해주기\n",
    "- [tensor].to(dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad3fd748db6c5122",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.750142100Z",
     "start_time": "2023-09-19T13:22:07.942487200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) torch.float32\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int8)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "torch.float64\n",
      "torch.int16\n",
      "double_f: tensor([0.9021, 0.3627, 0.9826, 0.5431, 0.1075], dtype=torch.float64)\n",
      "short_g: tensor([0, 0, 0, 0, 0], dtype=torch.int16)\n",
      "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(2,3)\n",
    "print(a, a.dtype)\n",
    "\n",
    "a_zeros = a.to(torch.int64)\n",
    "print(a_zeros)\n",
    "\n",
    "a_new = torch.ones(size=(2,3), dtype=torch.int8)\n",
    "print(a_new)\n",
    "\n",
    "a_pos = a_new.to(torch.int16)\n",
    "print(a_pos)\n",
    "\n",
    "\n",
    "print(\"\\n\", '*' * 50, \"\\n\")\n",
    "\n",
    "double_d = torch.ones(10, 2, dtype=torch.double)\n",
    "short_e = torch.tensor([[1, 2]], dtype=torch.short)\n",
    "\n",
    "double_d = torch.zeros(10, 2).double()\n",
    "short_e = torch.ones(10, 2).short()\n",
    "\n",
    "double_d = torch.zeros(10, 2).to(torch.double)\n",
    "short_e = torch.ones(10, 2).to(dtype=torch.short)\n",
    "\n",
    "double_d = torch.zeros(10, 2).type(torch.double)\n",
    "short_e = torch.ones(10, 2).type(dtype=torch.short)\n",
    "\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)\n",
    "\n",
    "double_f = torch.rand(5, dtype=torch.double) # 0,1 사이의 값으로 채워진, size 5인 double형의 tensor\n",
    "short_g = double_f.to(torch.short)\n",
    "multiply = double_f * short_g\n",
    "print(f\"double_f: {double_f}\\nshort_g: {short_g}\")\n",
    "print(multiply) # 더 큰 자료형으로 형변환 되는 듯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb789fd76b0d5357",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# f_tensor_operations.py\n",
    "Element-wise operations : 사이즈가 같은 두 텐서끼리의 add, sub, mul, div 연산은 각 자리수끼리의 연산결과를 리턴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b116366c165be47",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.750142100Z",
     "start_time": "2023-09-19T13:22:07.977495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "##############################\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "##############################\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "##############################\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(2, 3))\n",
    "t2 = torch.ones(size=(2, 3))\n",
    "t3 = torch.add(t1, t2)\n",
    "t4 = t1 + t2\n",
    "print(t3)\n",
    "print(t4)\n",
    "\n",
    "print(\"#\" * 30)\n",
    "\n",
    "t5 = torch.sub(t1, t2)\n",
    "t6 = t1 - t2\n",
    "print(t5)\n",
    "print(t6)\n",
    "\n",
    "print(\"#\" * 30)\n",
    "\n",
    "t7 = torch.mul(t1, t2)\n",
    "t8 = t1 * t2\n",
    "print(t7)\n",
    "print(t8)\n",
    "\n",
    "print(\"#\" * 30)\n",
    "\n",
    "t9 = torch.div(t1, t2)\n",
    "t10 = t1 / t2\n",
    "print(t9)\n",
    "print(t10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a41266d4ba21b1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "************\n",
    "# g_tensor_operations_mm.py\n",
    "torch.mul(input, other): '브로드캐스팅'을 동반한 element-wise multiplications\n",
    "torch.dot(input, other) : computes the dot product of two 1D tensors\n",
    "torch.mm(input, other): matrix multiplication without 'broadcasting'\n",
    "torch.bmm(input, other): performs a batch matrix multiplication without broadcasting\n",
    "\n",
    "\n",
    "<br><br>\n",
    "##### dot 연산\n",
    "dot() 연산은 만약 A = [a₁, a₂, a₃, ..., aₙ]과 B = [b₁, b₂, b₃, ..., bₙ]이라면,\n",
    "A와 B의 도트 곱은 다음과 같이 계산됩니다:\n",
    "A · B = a₁b₁ + a₂b₂ + a₃b₃ + ... + aₙbₙ\n",
    "\n",
    "<br><br>\n",
    "##### bmm:batch에 대하여\n",
    "특별히 bmm()에 들어오는 tensor는 {batch-size X n X m}, {batch-size X m X p} 형식이어야만 한다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b06ceb68efe7171",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.750142100Z",
     "start_time": "2023-09-19T13:22:08.005502300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.4807, 0.3612, 5.0622, 8.4695],\n",
      "        [2.5884, 2.7065, 4.1148, 6.8386]])\n",
      "tensor([[2., 2., 2., 2.]])\n",
      "tensor([[14.9614,  0.7224, 10.1244, 16.9389],\n",
      "        [ 5.1768,  5.4131,  8.2296, 13.6772]])\n",
      "tensor([[14.9614,  0.7224, 10.1244, 16.9389],\n",
      "        [ 5.1768,  5.4131,  8.2296, 13.6772]])\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "\n",
    "- torch.mul() 연산에 대하여 -\n",
    "ing2 = torch.ones(size=(2,2)) * 2 로 선언했을때도 브로드캐스팅이 되어 \n",
    "ing1과 mul() 연산이 가능할 줄 알았는데 그렇지 않았다.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "ing1 = torch.rand(size=(2,4)) * 10\n",
    "ing2 = torch.ones(size=(1,4)) * 2\n",
    "#ing2 = torch.ones(size=(2,2)) * 2 # 는 mul() 불가능함\n",
    "print(ing1, ing2, sep=\"\\n\")\n",
    "\n",
    "mul_scalar = torch.mul(ing1,2)\n",
    "print(mul_scalar)\n",
    "\n",
    "mul_vec = torch.mul(ing1, ing2) # Element-wise 연산이라서, 자연히 \n",
    "print(mul_vec)\n",
    "t1 = torch.mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "109303db3569a064",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.751154100Z",
     "start_time": "2023-09-19T13:22:08.022505600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 5, 7, 9])\n",
      "tensor([2, 2, 2, 2, 2])\n",
      "\n",
      "tensor(50)\n",
      "tensor([1, 3, 5, 7, 9])\n",
      "tensor([2, 2, 2, 2, 2])\n",
      "------------------------------\n",
      "tensor(7) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dot()연산에 대해\n",
    "\n",
    "dot() 연산은 만약 A = [a₁, a₂, a₃, …, aₙ]과 B = [b₁, b₂, b₃, …, bₙ]이라면, A와 B의 도트 곱은 다음과 같이 계산됩니다: A · B = a₁b₁ + a₂b₂ + a₃b₃ + … + aₙbₙ\n",
    "\n",
    "broadcasting : X\n",
    "'''\n",
    "\n",
    "\n",
    "int1 = torch.arange(1,10, 2) # [1,3,5,7,9]\n",
    "int2 = torch.ones(size=(5,), dtype=torch.int64) * 2\n",
    "int_brd = torch.ones(size=(1,), dtype=torch.int64) * 2\n",
    "print(int1, int2, sep=\"\\n\")\n",
    "\n",
    "print()\n",
    "dot = torch.dot(int1, int2)\n",
    "print(dot, int1, int2, sep=\"\\n\")\n",
    "\n",
    "'''\n",
    "print(\"dot() 연산 broadcasting -test\")\n",
    "dot = torch.dot(int1, int_brd)\n",
    "print(dot, int1, int_brd, sep=\"\\n\")\n",
    "'''\n",
    "\n",
    "print(\"-\"*30)\n",
    "t1 = torch.dot(\n",
    "  torch.tensor([2, 3]), torch.tensor([2, 1])\n",
    ")\n",
    "print(t1, t1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b321b02282bda8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.751154100Z",
     "start_time": "2023-09-19T13:22:08.036509900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1860, -0.4872, -1.9286, -1.1155],\n",
      "        [ 2.2702,  0.1513, -0.6572,  0.0337]])\n",
      "tensor([[ 0.5095, -1.2934],\n",
      "        [ 0.0326, -1.9171],\n",
      "        [ 1.1867, -1.0347],\n",
      "        [ 1.6391, -0.5500]])\n",
      "tensor([[-4.7372,  5.0770],\n",
      "        [ 0.4370, -2.5649]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "torch.mm() 연산은 2D Tensor끼리의 연산을 지원하며, 브로드캐스팅이 없다.\n",
    "(nXm, mXp)이면 결과로 (nXp)가 나온다. \n",
    "'''\n",
    "\n",
    "t2 = torch.randn(2, 4) # randn() 함수는 0,1 사이의 표준정규분포를 따른다.\n",
    "# t2 = torch.randn(2, 2) # 브로드캐스팅 안됌\n",
    "t3 = torch.randn(4, 2)\n",
    "t4 = torch.mm(t2, t3)\n",
    "print(t2, t3, t4, t4.size(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "499f2d8fec0ba0e0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.751154100Z",
     "start_time": "2023-09-19T13:22:08.050512300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "'''torch.bmm()'''\n",
    "\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(10, 4, 5)\n",
    "# print(t5, t6, sep=\"\\n\")\n",
    "t7 = torch.bmm(t5, t6)\n",
    "print(t7.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c727bb7aceadbb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# h_tensor_operations_matmul.py\n",
    "\n",
    "matmul과 mm의 차이\n",
    "\n",
    "- torch.matmul(): 이 함수는 행렬 곱셈뿐만 아니라 다양한 다차원 배열 간의 곱셈을 다룰 수 있는 범용적인 행렬 곱셈 함수입니다. 따라서 2D 행렬뿐만 아니라 고차원의 텐서에 대해서도 작동합니다. torch.matmul()은 <b>브로드캐스팅 규칙을 따르며, 고차원 텐서에 대해서도 올바르게 작동하도록 설계되었습니다.</b>\n",
    "- torch.mm(): 이 함수는 <b>오직 2D 행렬 간의 곱셈</b>만을 수행하는 함수입니다. 따라서 두 개의 2D 행렬을 인자로 받아야 하며, 두 행렬의 내적을 계산합니다. 고차원 텐서에 대해서는 작동하지 않습니다.\n",
    "\n",
    "마지막 차원의 size가 맞아야 하고, 그 두 벡터끼리 내적의 결과로 스칼라가 나오기 때문에 결과값의 차원은 마지막 차원을 뺀 나머지 차원만 남는다.\n",
    "예) matmul(5x3x4, 4) ==> (5x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19b1dea26252fe6b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.751154100Z",
     "start_time": "2023-09-19T13:22:08.070517100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8802, -2.2156,  0.3741]) tensor([-0.2782,  1.0238,  0.0738]) torch.Size([3])\n",
      "\n",
      "cnt: tensor([ 0.5231, -2.2683,  0.0276]), res: -1.7175251245498657\n",
      "tensor(-1.7175)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# vector x vector: dot product\n",
    "t1 = torch.randn(3) # 1d\n",
    "t2 = torch.randn(3) # 1d\n",
    "print(t1, t2, t1.size())\n",
    "print()\n",
    "\n",
    "# dot 연산 확인\n",
    "cnt = torch.tensor(list(map(lambda x,y : x*y , t1,t2)))\n",
    "res = sum(cnt) \n",
    "print(f'cnt: {cnt}, res: {res}')\n",
    "\n",
    "print(torch.matmul(t1, t2))\n",
    "print(torch.matmul(t1, t2).size())  # torch.Size([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62a30d104f59a31f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.766145900Z",
     "start_time": "2023-09-19T13:22:08.091521600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3125,  0.2971, -0.7993, -1.2179],\n",
      "        [-0.4842,  1.1103,  0.0608, -0.0633],\n",
      "        [-0.0388, -0.1641,  0.0297, -1.3805]])\n",
      "tensor([ 0.6036,  1.2310,  0.8264, -1.4009])\n",
      "tensor([1.6000, 1.2135, 1.7331])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# matrix x vector: broadcasted dot\n",
    "t3 = torch.randn(3, 4)\n",
    "# t4 = torch.randn(3) # 이렇게는 브로드캐스팅 안됌. 마지막 차원에 맞춰야 하는 듯\n",
    "t4 = torch.randn(4)\n",
    "print(t3, t4, sep=\"\\n\")\n",
    "print(torch.matmul(t3,t4))\n",
    "print(torch.matmul(t3, t4).size())  # torch.Size([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61409d78ed08693b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.766145900Z",
     "start_time": "2023-09-19T13:22:08.114526800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x vector: broadcasted dot\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(4)\n",
    "# t6 = torch.randn(3,4) # Error\n",
    "# t6 = torch.randn(4,5) # OK\n",
    "print(torch.matmul(t5, t6).size())  # torch.Size([10, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a885eaf2076e9672",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.766145900Z",
     "start_time": "2023-09-19T13:22:08.129530100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x batched matrix: bmm\n",
    "t7 = torch.randn(10, 3, 4)\n",
    "t8 = torch.randn(10, 4, 5)\n",
    "print(torch.matmul(t7, t8).size())  # torch.Size([10, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe0be9c39d361d4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.767156400Z",
     "start_time": "2023-09-19T13:22:08.145534200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x matrix: bmm\n",
    "t9 = torch.randn(10, 3, 4)\n",
    "t10 = torch.randn(4, 5)\n",
    "print(torch.matmul(t9, t10).size())  # torch.Size([10, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98206c954999cb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# i_tensor_broadcasting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40aa18e9592ee083",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.767156400Z",
     "start_time": "2023-09-19T13:22:08.162538100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n",
      "################################################## 1\n",
      "tensor([[-4, -4],\n",
      "        [-2, -1],\n",
      "        [ 6,  5]])\n",
      "################################################## 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1 * t2)\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
    "t4 = torch.tensor([4, 5])\n",
    "print(t3 - t4)\n",
    "\n",
    "print(\"#\" * 50, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "401343009f5fe00b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.767156400Z",
     "start_time": "2023-09-19T13:22:08.177541300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n",
      "################################################## 3\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t5 + 2.0)  # t5.add(2.0)\n",
    "print(t5 - 2.0)  # t5.sub(2.0)\n",
    "print(t5 * 2.0)  # t5.mul(2.0)\n",
    "print(t5 / 2.0)  # t5.div(2.0)\n",
    "\n",
    "print(\"#\" * 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6755ab6613bdec5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.768154900Z",
     "start_time": "2023-09-19T13:22:08.193544600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "  return x / 255\n",
    "\n",
    "\n",
    "t6 = torch.randn(3, 28, 28)\n",
    "print(normalize(t6).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3141d74ade3c0ee1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.768154900Z",
     "start_time": "2023-09-19T13:22:08.209548300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 4\n",
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor([[6, 7],\n",
      "        [2, 5]])\n",
      "tensor([[8, 6],\n",
      "        [5, 3]])\n",
      "tensor([[ 8,  9],\n",
      "        [ 7, 10]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 4)\n",
    "\n",
    "t7 = torch.tensor([[1, 2], [0, 3]])  # torch.Size([2, 2])\n",
    "t8 = torch.tensor([[3, 1]])  # torch.Size([1, 2])\n",
    "t9 = torch.tensor([[5], [2]])  # torch.Size([2, 1])\n",
    "t10 = torch.tensor([7])  # torch.Size([1])\n",
    "print(t7 + t8)   # >>> tensor([[4, 3], [3, 4]])\n",
    "print(t7 + t9)   # >>> tensor([[6, 7], [2, 5]])\n",
    "print(t8 + t9)   # >>> tensor([[8, 6], [5, 3]])\n",
    "print(t7 + t10)  # >>> tensor([[ 8, 9], [ 7, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a1f6e3a1594a8f19",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.768154900Z",
     "start_time": "2023-09-19T13:22:08.221551100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 5\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "4칙연산 연산에 대해서는 broadcasting (o) \n",
    "단, 동일 차원의 맞지 않는 사이즈가 서로 배수관계여야 한다\n",
    "'''\n",
    "\n",
    "print(\"#\" * 50, 5)\n",
    "\n",
    "t11 = torch.ones(4, 3, 2)\n",
    "t12 = t11 * torch.rand(3, 2)  # 3rd & 2nd dims identical to t11, dim 0 absent\n",
    "print(t12.shape)\n",
    "\n",
    "t13 = torch.ones(4, 3, 2)\n",
    "t14 = t13 * torch.rand(3, 1)  # 3rd dim = 1, 2nd dim is identical to t13\n",
    "print(t14.shape)\n",
    "\n",
    "t15 = torch.ones(4, 3, 2)\n",
    "t16 = t15 * torch.rand(1, 2)  # 3rd dim is identical to t15, 2nd dim is 1\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.ones(5, 3, 4, 1)\n",
    "t18 = torch.rand(3, 1, 1)  # 2nd dim is identical to t17, 3rd and 4th dims are 1\n",
    "print((t17 + t18).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5d528eefc595060",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.769145900Z",
     "start_time": "2023-09-19T13:22:08.237555500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 6\n",
      "torch.Size([5, 3, 4, 1])\n",
      "torch.Size([3, 1, 7])\n",
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 6)\n",
    "\n",
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 = torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size())  # torch.Size([5, 3, 4, 1])\n",
    "\n",
    "t21 = torch.empty(1)\n",
    "t22 = torch.empty(3, 1, 7)\n",
    "print((t21 + t22).size())  # torch.Size([3, 1, 7])\n",
    "\n",
    "t23 = torch.ones(3, 3, 3)\n",
    "t24 = torch.ones(3, 1, 3)\n",
    "print((t23 + t24).size())  # torch.Size([3, 3, 3])\n",
    "\n",
    "# t25 = torch.empty(5, 2, 4, 1)\n",
    "# t26 = torch.empty(3, 1, 1)\n",
    "# print((t25 + t26).size())\n",
    "# RuntimeError: The size of tensor a (2) must match\n",
    "# the size of tensor b (3) at non-singleton dimension 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f96e355f781aa36",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.769145900Z",
     "start_time": "2023-09-19T13:22:08.253559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 7\n",
      "tensor([5., 5., 5., 5.])\n",
      "tensor([25., 25., 25., 25.])\n",
      "tensor([  1.,   4.,  27., 256.])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 7)\n",
    "\n",
    "t27 = torch.ones(4) * 5\n",
    "print(t27)  # >>> tensor([ 5, 5, 5, 5])\n",
    "\n",
    "t28 = torch.pow(t27, 2)\n",
    "print(t28)  # >>> tensor([ 25, 25, 25, 25])\n",
    "\n",
    "exp = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
    "a = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
    "t29 = torch.pow(a, exp)\n",
    "print(t29)  # >>> tensor([   1.,    4.,   27.,  256.])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29c2da8d2afa33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# j_tensor_indexing_slicing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e3a5d152540b4c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.769145900Z",
     "start_time": "2023-09-19T13:22:08.273563700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8, 9])\n",
      "tensor([ 1,  6, 11])\n",
      "tensor(7)\n",
      "tensor([ 4,  9, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9],\n",
    "   [10, 11, 12, 13, 14]]\n",
    ") # size= (3,5)\n",
    "\n",
    "print(x[1])  # >>> tensor([5, 6, 7, 8, 9])\n",
    "print(x[:, 1])  # >>> tensor([1, 6, 11])\n",
    "print(x[1, 2])  # >>> tensor(7)\n",
    "print(x[:, -1])  # >>> tensor([4, 9, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d4190b60c55e5c8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.770147500Z",
     "start_time": "2023-09-19T13:22:08.286566900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 1\n",
      "tensor([[ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]])\n",
      "tensor([[ 8,  9],\n",
      "        [13, 14]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 1)\n",
    "\n",
    "print(x[1:])  # >>> tensor([[ 5,  6,  7,  8,  9], [10, 11, 12, 13, 14]])\n",
    "print(x[1:, 3:])  # >>> tensor([[ 8,  9], [13, 14]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d52310a0094a4d1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.770147500Z",
     "start_time": "2023-09-19T13:22:08.301570300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 2\n",
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 2)\n",
    "\n",
    "y = torch.zeros((6, 6))\n",
    "y[1:4, 2] = 1\n",
    "print(y)\n",
    "\n",
    "print(y[1:4, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20caf3a5696b9d77",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.770147500Z",
     "start_time": "2023-09-19T13:22:08.320575100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 3\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 3, 4, 5]])\n",
      "tensor([[3, 4],\n",
      "        [6, 7]])\n",
      "tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 0, 0, 5],\n",
      "        [5, 0, 0, 8]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 3)\n",
    "\n",
    "z = torch.tensor(\n",
    "  [[1, 2, 3, 4],\n",
    "   [2, 3, 4, 5],\n",
    "   [5, 6, 7, 8]]\n",
    ")\n",
    "print(z[:2]) #tensor([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "print(z[1:, 1:3]) #\n",
    "print(z[:, 1:])\n",
    "\n",
    "z[1:, 1:3] = 0\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb8146b4d14ef0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# k_tensor_reshaping.py\n",
    "\n",
    "torch.tensor.view(size=(..))\n",
    "torch.tensor.reshape(size=(..))\n",
    "\n",
    "squeeze() : tensor의 모든 1차원 데이터를 flatten() 시킴\n",
    "    즉, 1차원이 없도록 만듦.\n",
    "    - squeeze(dim=N) : 특정 차원의 dimension이 1이면 차원 삭제 \n",
    "    \n",
    "unsqueeze(dim) : 특정 위치의 차원을 한번 감쌈 (squeeze의 반대) \n",
    "\n",
    "flatten() : 1차원 텐서로 만듦\n",
    "    - torch.flatten(tensor, start_dim=#)\n",
    "        start_dim = 이 인덱스를 기점으로 하위 차원의 값들을 flatten\n",
    "\n",
    "permute() : 다차원 텐서의 차원을 일일히 지정하여 바꾸는 것\n",
    "\n",
    "transpose(): 행과 열을 입력받아 두 차원을 바꿔주는 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5633b95810206a80",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.770147500Z",
     "start_time": "2023-09-19T13:22:08.333578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = t1.view(3, 2)  # Shape becomes (3, 2)\n",
    "t3 = t1.reshape(1, 6)  # Shape becomes (1, 6)\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.arange(8).view(2, 4)  # Shape becomes (2, 4)\n",
    "t5 = torch.arange(6).view(2, 3)  # Shape becomes (2, 3)\n",
    "print(t4)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "379c4353585308c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.772146800Z",
     "start_time": "2023-09-19T13:22:08.352582600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 1\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 1)\n",
    "\n",
    "# Original tensor with shape (1, 3, 1)\n",
    "t6 = torch.tensor([[[1], [2], [3]]])\n",
    "\n",
    "# Remove all dimensions of size 1\n",
    "t7 = t6.squeeze()  # Shape becomes (3,)\n",
    "\n",
    "# Remove dimension at position 0\n",
    "t8 = t6.squeeze(0)  # Shape becomes (3, 1)\n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "300b10c4689e9920",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.772146800Z",
     "start_time": "2023-09-19T13:22:08.365585100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 2\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]]) torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 2)\n",
    "\n",
    "# Original tensor with shape (3,)\n",
    "t9 = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Add a new dimension at position 1\n",
    "t10 = t9.unsqueeze(1)  # Shape becomes (3, 1)\n",
    "print(t10)\n",
    "\n",
    "t11 = torch.tensor(\n",
    "  [[1, 2, 3],\n",
    "   [4, 5, 6]]\n",
    ")\n",
    "t12 = t11.unsqueeze(1)  # Shape becomes (2, 1, 3)\n",
    "print(t12, t12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3e60a1cf5e3507d2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.772146800Z",
     "start_time": "2023-09-19T13:22:08.385589800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 3\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 3)\n",
    "\n",
    "# Original tensor with shape (2, 3)\n",
    "t13 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Flatten the tensor\n",
    "t14 = t13.flatten()  # Shape becomes (6,)\n",
    "\n",
    "print(t14)\n",
    "\n",
    "# Original tensor with shape (2, 2, 2)\n",
    "t15 = torch.tensor([[[1, 2],\n",
    "                     [3, 4]],\n",
    "                    [[5, 6],\n",
    "                     [7, 8]]])\n",
    "t16 = torch.flatten(t15)\n",
    "\n",
    "t17 = torch.flatten(t15, start_dim=1)\n",
    "\n",
    "print(t16)\n",
    "print(t17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ad3249a893292b8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.773146500Z",
     "start_time": "2023-09-19T13:22:08.401594600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 4\n",
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 4)\n",
    "\n",
    "t18 = torch.randn(2, 3, 5)\n",
    "print(t18.shape)  # >>> torch.Size([2, 3, 5])\n",
    "print(torch.permute(t18, (2, 0, 1)).size())  # >>> torch.Size([5, 2, 3])\n",
    "\n",
    "# Original tensor with shape (2, 3)\n",
    "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Permute the dimensions\n",
    "t20 = torch.permute(t19, dims=(0, 1))  # Shape becomes (2, 3) still\n",
    "t21 = torch.permute(t19, dims=(1, 0))  # Shape becomes (3, 2)\n",
    "print(t20)\n",
    "print(t21)\n",
    "\n",
    "# Transpose the tensor\n",
    "t22 = torch.transpose(t19, 0, 1)  # Shape becomes (3, 2)\n",
    "\n",
    "print(t22)\n",
    "\n",
    "t23 = torch.t(t19)  # Shape becomes (3, 2)\n",
    "\n",
    "print(t23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f04a03b1db43f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# l_tensor_concat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "58e4b76d4456ba3a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.773146500Z",
     "start_time": "2023-09-19T13:22:08.416596600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.zeros([2, 3, 3])\n",
    "t3 = torch.zeros([2, 2, 3])\n",
    "\n",
    "t4 = torch.cat([t1, t2, t3], dim=1)\n",
    "print(t4.shape) # torch.Size([2, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5edc9b8f5271553d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.773146500Z",
     "start_time": "2023-09-19T13:22:08.429600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 1\n",
      "torch.Size([8])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t5 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t6 = torch.arange(3, 8)  # tensor([3, 4, 5, 6, 7])\n",
    "\n",
    "t7 = torch.cat((t5, t6), dim=0)\n",
    "print(t7.shape)  # >>> torch.Size([8])\n",
    "print(t7)  # >>> tensor([0, 1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bc63b6732a49e05d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.773146500Z",
     "start_time": "2023-09-19T13:22:08.445171400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 2\n",
      "torch.Size([4, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([2, 6])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 2)\n",
    "\n",
    "t8 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t9 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "# 2차원 텐서간 병합\n",
    "t10 = torch.cat((t8, t9), dim=0)\n",
    "print(t10.size())  # >>> torch.Size([4, 3])\n",
    "print(t10)\n",
    "# >>> tensor([[ 0,  1,  2],\n",
    "#             [ 3,  4,  5],\n",
    "#             [ 6,  7,  8],\n",
    "#             [ 9, 10, 11]])\n",
    "\n",
    "t11 = torch.cat((t8, t9), dim=1)\n",
    "print(t11.size())  # >>>torch.Size([2, 6])\n",
    "print(t11)\n",
    "# >>> tensor([[ 0,  1,  2,  6,  7,  8],\n",
    "#             [ 3,  4,  5,  9, 10, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f3414cf217ede0a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.774148500Z",
     "start_time": "2023-09-19T13:22:08.461396300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 3\n",
      "torch.Size([6, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "torch.Size([2, 9])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
      "        [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 3)\n",
    "\n",
    "t12 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t13 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t14 = torch.arange(12, 18).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "t15 = torch.cat((t12, t13, t14), dim=0)\n",
    "print(t15.size())  # >>> torch.Size([6, 3])\n",
    "print(t15)\n",
    "# >>> tensor([[ 0,  1,  2],\n",
    "#             [ 3,  4,  5],\n",
    "#             [ 6,  7,  8],\n",
    "#             [ 9, 10, 11],\n",
    "#             [12, 13, 14],\n",
    "#             [15, 16, 17]])\n",
    "\n",
    "t16 = torch.cat((t12, t13, t14), dim=1)\n",
    "print(t16.size())  # >>> torch.Size([2, 9])\n",
    "print(t16)\n",
    "# >>> tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
    "#             [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb773d1059a4d37b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.774148500Z",
     "start_time": "2023-09-19T13:22:08.481402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 4\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 2, 6])\n",
      "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
      "         [ 3,  4,  5,  9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 4)\n",
    "\n",
    "t17 = torch.arange(0, 6).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "t18 = torch.arange(6, 12).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "\n",
    "t19 = torch.cat((t17, t18), dim=0)\n",
    "print(t19.size())  # >>> torch.Size([2, 2, 3])\n",
    "print(t19)\n",
    "# >>> tensor([[[ 0,  1,  2],\n",
    "#              [ 3,  4,  5]],\n",
    "#             [[ 6,  7,  8],\n",
    "#              [ 9, 10, 11]]])\n",
    "\n",
    "t20 = torch.cat((t17, t18), dim=1)\n",
    "print(t20.size())  # >>> torch.Size([1, 4, 3])\n",
    "print(t20)\n",
    "# >>> tensor([[[ 0,  1,  2],\n",
    "#              [ 3,  4,  5],\n",
    "#              [ 6,  7,  8],\n",
    "#              [ 9, 10, 11]]])\n",
    "\n",
    "t21 = torch.cat((t17, t18), dim=2)\n",
    "print(t21.size())  # >>> torch.Size([1, 2, 6])\n",
    "print(t21)\n",
    "# >>> tensor([[[ 0,  1,  2,  6,  7,  8],\n",
    "#              [ 3,  4,  5,  9, 10, 11]]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbef2c59cb5f2d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# m_tensor_stacking.py\n",
    "torch.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd75513d14636174",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.775147800Z",
     "start_time": "2023-09-19T13:22:08.496405300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 3, 2]) True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]]) # 2, 3\n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]]) # 2, 3\n",
    "\n",
    "t3 = torch.stack([t1, t2], dim=0)\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0) # 2,2,3\n",
    "# cat((1,2,3), (1,2,3), dim=0) ==> (2,2,3)\n",
    "print(t3.shape, t3.equal(t4))\n",
    "\n",
    "t5 = torch.stack([t1, t2], dim=1)\n",
    "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1)\n",
    "# cat((2, 1, 3), (2, 1, 3), dim=1) ==> (2,2,3)\n",
    "print(t5.shape, t5.equal(t6))\n",
    "\n",
    "t7 = torch.stack([t1, t2], dim=2)\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2)\n",
    "# cat((2,3,1), (2,3,1), dim=2)\n",
    "print(t7.shape, t7.equal(t8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "43ae4a405f8172b8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.793378400Z",
     "start_time": "2023-09-19T13:22:08.512408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 1\n",
      "torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "True\n",
      "torch.Size([3, 2])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"#\" * 50, 1)\n",
    "\n",
    "t9 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t10 = torch.arange(3, 6)  # tensor([3, 4, 5])\n",
    "\n",
    "print(t9.size(), t10.size())\n",
    "# >>> torch.Size([3]) torch.Size([3])\n",
    "\n",
    "t11 = torch.stack((t9, t10), dim=0)\n",
    "print(t11.size())  # >>> torch.Size([2,3])\n",
    "print(t11)\n",
    "# >>> tensor([[0, 1, 2],\n",
    "#             [3, 4, 5]])\n",
    "\n",
    "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0)\n",
    "print(t11.equal(t12))\n",
    "# >>> True\n",
    "\n",
    "t13 = torch.stack((t9, t10), dim=1)\n",
    "print(t13.size())  # >>> torch.Size([3,2])\n",
    "print(t13)\n",
    "# >>> tensor([[0, 3],\n",
    "#             [1, 4],\n",
    "#             [2, 5]])\n",
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1)\n",
    "print(t13.equal(t14))\n",
    "# >>> True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe36cac5d1b5d89",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# n_tensor_vstack_hstack.py \n",
    "\n",
    "virtical VS horizontal\n",
    "\n",
    "vstack : 최상위차원에 스택을 쌓는 느낌 \n",
    "hstack : 상위 2번째 차원에 스택을 쌓는 느낌 ==> 모든 텐서가 동일한 행의 개수를 가져야함\n",
    "(인자로 list 형식도 가능함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e461d0a389bb89b5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:09.802392Z",
     "start_time": "2023-09-19T13:22:08.523411500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.tensor([1,2,3])\n",
    "t2 = torch.tensor([4,5,6])\n",
    "t3 = torch.vstack((t1,t2))\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.tensor([[1],[2],[3]]) # 3,1\n",
    "t5 = torch.tensor([[4],[5],[6]]) # 3,1\n",
    "t6 = torch.vstack((t4,t5))\n",
    "print(t6)\n",
    "t6 = torch.vstack([t4,t5])\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "874251a4d385cd96",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:10.655727500Z",
     "start_time": "2023-09-19T13:22:08.543416200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([4, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.tensor ([\n",
    "[[1, 2, 3], [4, 5, 6]],\n",
    "[[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "\n",
    "print(t7.shape)\n",
    "\n",
    "t8 = torch.tensor([\n",
    "[[13, 14, 15], [16, 17, 18]],\n",
    "[[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t8.shape)\n",
    "# >>> (2, 2, 3)\n",
    "\n",
    "t9 = torch.vstack ([t7, t8])\n",
    "print(t9.shape)\n",
    "# >>> (4, 2, 3)\n",
    "print(t9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c430b28cb8eb7de",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:10.656727700Z",
     "start_time": "2023-09-19T13:22:08.555418300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t10 = torch.tensor([1, 2, 3])\n",
    "t11 = torch.tensor([4, 5, 6])\n",
    "t12 = torch.hstack((t10, t11))\n",
    "print(t12)\n",
    "# >>> tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "t13 = torch.tensor([[1], [2], [3]])\n",
    "t14 = torch.tensor([[4], [5], [6]])\n",
    "t15 = torch.hstack((t13, t14)) # 3, 2\n",
    "print(t15)\n",
    "# >>> tensor([[1, 4],\n",
    "# [2, 5],\n",
    "# [3, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b813818fa555fe3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:10.656727700Z",
     "start_time": "2023-09-19T13:22:08.575423400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12],\n",
      "         [19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "t16 = torch.tensor([\n",
    "[[1, 2, 3], [4, 5, 6]],\n",
    "[[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t16.shape)\n",
    "# >>> (2, 2, 3)\n",
    "\n",
    "t17 = torch.tensor([\n",
    "[[13, 14, 15], [16, 17, 18]],\n",
    "[[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t17.shape)\n",
    "# >>> (2, 2, 3)\n",
    "\n",
    "t18 = torch.hstack([t16, t17])\n",
    "print(t18.shape)\n",
    "# >>> (2, 4, 3)\n",
    "\n",
    "print(t18)\n",
    "# >>> tensor([[[ 1, 2, 3],\n",
    "# [ 4, 5, 6],\n",
    "# [13, 14, 15],\n",
    "# [16, 17, 18]],\n",
    "# [[ 7, 8, 9],\n",
    "# [10, 11, 12],\n",
    "# [19, 20, 21],\n",
    "# [22, 23, 24]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a2f1628008389e8f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T13:22:10.656727700Z",
     "start_time": "2023-09-19T13:22:08.590426900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.zeros([3,4,5,2])\n",
    "m2 = torch.zeros([3,4,5,2])\n",
    "res = torch.hstack([m1,m2])\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595c42116971212",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-----------------------------------\n",
    "# 숙제 후기\n",
    "\n",
    "전에 numpy를 배운 적이 있지만 다 까먹었다. 교수님께서 numpy와 tensor가 비슷한 측면이 많다고 하셨는데, 여러모로 그런거 같다고 느꼈다. \n",
    "\n",
    "확실히 행렬이 들어가면서 선형대수학 시간에 배웠던 것들이 많이 보였다. 덕분에 과제를 수행하면서 내적과 외적의 의미를 다시한번 찾아보고 복습하는 계기가 되었다.\n",
    "\n",
    "교수님께서 우리를 가르치실 때 이 많은 함수들을 모두 다 외우라고 시키시기 보다는 어떤 함수가 중요한 함수이고 어떤 부분이 중요한지를 짚어주셔서 공부하기에 한참 수월한 느낌을 받았다. \n",
    "\n",
    "비록 코드를 다 주셨지만 일일히 따라 쳐보면서 공부했더니 도움이 많이 되었다. \n",
    "예를 들어 size를 tuple로 넘겨주는 코드를 주로 보다가 \n",
    "<code>torch.tensor([1,2,3])</code>\n",
    " 같은 것을 보니 Size(3,) 짜리 텐서가 아닌 Size(1,2,3) 짜리 텐서로 생각하는 등의 헤프닝이 있었다.\n",
    "\n",
    "하지만, 역설적이게도, 사실 나는 무작정 따라 치기보다는 머리로 이해하는 과정이 더욱 중요하다고 생각한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
